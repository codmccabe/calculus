\documentclass{ximera}

\input{../preamble.tex}

\outcome{Understand the geometric basis of the method of Lagrange Multipliers.}

\outcome{Use Lagrange multipliers to solve sontrained optimization problems.}

\outcome{Define the Lagrangian.}

\title[Dig-In:]{Lagrange multiplies}

\begin{document}
\begin{abstract}
  We give a new method of finding extrema.
\end{abstract}

\maketitle

Throughout this course, we hope it has become apparent that when given
a problem:
\begin{quote}
  \textbf{There is more than one way to solve it.}
\end{quote}
The method of Lagrange multipliers tells us that to maximize a
function constrained to a curve, we need to find where the gradient of the function is perpendicular to the curve.

Previously, we defined the gradient of the function is perpendicular to a curve.

\begin{example}
Let $F(x,y) = 4x^3+4y^2-4x$ and let $C$ the set
\[
C = \{(x,y):x^2 + y^2 =1\}
\]
Find the maximum and minimum values of $F$ on $C$.
\end{example}

In the context of a Buisness Calculus course the first step may seem impossible.

Nevertheless, there is another way. It is called the method of
\textit{Lagrange multipliers}. This method is named after the
mathematician \link[Joseph-Louis
  Lagrange]{http://en.wikipedia.org/wiki/Joseph-Louis_Lagrange}. This
method relies on the geometric properties of the \textit{gradient
  vector}. Recall: There are three things you must know about the
gradient vector:
\begin{itemize}
\item $\grad F = \vector{\pp[F]{x_1},\pp[F]{x_2},\dots,\pp[F]{x_n}}$.
\item $\grad F(\vec{x})$ points in the direction that one must leave
  $\vec{x}$ in order to see the initial greatest increase in $F$.
\item $\grad F(\vec{x})$ points in the direction that is perpendicular
  to any level surface of $F$.
\end{itemize}

It is the last two facts that we will think about now.  Below we see
level curves for some function $F:\R^2\to\R$ along with a constraining
curve that we will call $S$:
\begin{image}
  \begin{tikzpicture}
    \begin{axis}%
      [
        unit vector ratio*=1 1 1,
	ymin=-.2,ymax=4.5,
        width=5in,
	xmin=-4.5,xmax=4.5,
        axis lines=none,
      ]
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({cos(x)},{sin(x)});
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({2*cos(x)},{2*sin(x)});
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({3*cos(x)},{3*sin(x)});
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({4*cos(x)},{4*sin(x)});

      \addplot[ultra thick, penColor4,smooth] {x^2+1};

      \node[penColor,fill=white] at (axis cs:-.7,.7) {$7$};
      \node[penColor,fill=white] at (axis cs:-1.4,1.4) {$6$};
      \node[penColor,fill=white] at (axis cs:-2.1,2.1) {$5$};
      \node[penColor,fill=white] at (axis cs:-2.8,2.8) {$4$};

      \node[penColor4] at (axis cs:2,4) {$S$};
      \node[penColor] at (axis cs:-3.8,2) {$F$};
    \end{axis}
  \end{tikzpicture}
\end{image}

Let's add vectors to our graph that point in the direction of $\grad
F(x,y)$.  Since we know that the gradient vector is perpendicular to
level curves, we can do this \textit{without} computation.
\begin{image}
  \begin{tikzpicture}
    \begin{axis}%
      [
        unit vector ratio*=1 1 1,
	ymin=-.2,ymax=4.5,
        width=5in,
	xmin=-4.5,xmax=4.5,
        axis lines=none,
      ]
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({cos(x)},{sin(x)});
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({2*cos(x)},{2*sin(x)});
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({3*cos(x)},{3*sin(x)});
      \addplot[ultra thick, penColor,smooth,domain=0:180] ({4*cos(x)},{4*sin(x)});

      \addplot[ultra thick, penColor4,smooth] {x^2+1};

      \node[penColor,fill=white] at (axis cs:-.7,.7) {$7$};
      \node[penColor,fill=white] at (axis cs:-1.4,1.4) {$6$};
      \node[penColor,fill=white] at (axis cs:-2.1,2.1) {$5$};
      \node[penColor,fill=white] at (axis cs:-2.8,2.8) {$4$};

      \node[penColor4] at (axis cs:2,4) {$S$};
      \node[penColor] at (axis cs:-3.8,2) {$F$};

      \addplot[penColor2,ultra thick, ->] coordinates{(-1.63,3.65) (-1.22,2.74)};
      \addplot[penColor2,ultra thick, ->] coordinates{(1.63,3.65) (1.22,2.74)};

      \addplot[penColor2,ultra thick, ->] coordinates{(-1.3,2.7) (-.87,1.8)};
      \addplot[penColor2,ultra thick, ->] coordinates{(1.3,2.7) (.87,1.8)};

      \addplot[penColor2,ultra thick, ->] coordinates{(-.9,1.8) (-.45,.91)};
      \addplot[penColor2,ultra thick, ->] coordinates{(.9,1.8) (.45,.91)};

      \addplot[penColor2,ultra thick, ->] coordinates{(0,1) (0,0)};
    \end{axis}
  \end{tikzpicture}
\end{image}
If for some point $(x,y)$ on $S$ the gradient $\grad F(x,y)$ points in
the ``general'' direction of the tangent vectors of $S$, then $(x,y)$
\textbf{cannot} give an extremal value of $F$, as moving along $S$
will either increase or decrease the value of $F$. Here's the upshot:
\begin{quote}
  \textbf{The only candidates for local extrema occur when the
    gradient of $F$ is perpendicular to $S$.}
\end{quote}
How do we find these points? To do this, we will imagine that $S$ is a
level curve for some other function $G:\R^2\to\R$, and define $S$ as:
\[
S = \{(x,y):G(x,y)= c\}
\]
now, the candidates for extrema of $F$ when constrained to a curve $S$
are found by finding $(x,y)$ such that
\[
\grad F(x,y) =  \lambda \cdot \grad G(x,y)
\]
since $(x,y)$ that satisfy this equation are those where the gradient
vectors of $F$ are perpendicular to the level curve $G(x,y)= c$. This
is the essence of the method of Lagrange multipliers.

\begin{theorem}[Lagrange Multipliers]
  Let $F:\R^n\to\R$, $G:\R^n\to\R$, $\grad G(\vec{x}) \ne \vec{0}$,
  and let $S$ be the constraint, or level set,
  \[
  S = \{\vec{x}: G(\vec{x}) = c\}
  \]
  If $F$ has extrema when constrained to $S$ at $\vec{x}$, then
  \[
  \grad F(\vec{x}) = \lambda \cdot \grad G(\vec{x})
  \]
  for some number $\lambda$.
\end{theorem}

\begin{example}
  Let $F(x,y)=x^2+4y^2-2x+8y$ and let $C$ the set
  \[
    C=\{ (x,y) : x+2y=7 \}
  \]

  Find the minimum value of $F$ on $C$.
  \begin{explanation}
    First, set $G(x,y)=x+2y-7$ and notice $G(x,y)=0$ since we are constrained to all $x$ and $y$ such that $x+2y=7$.

    Second, calculate the gradients of both $F$ and $G$:
    \[
      \grad F(x,y) = \vector{2x-2,8y+8}
    \]
    and
    \[
      \grad G(x,y) = \vector{1,2}
    \]
    which then gives the eqution:
    \[
      \vector{2x-2,8y+8}=\lambda \vector{1,2}.
    \]
    That is,
    \begin{align*}
      2x - 2 & = \lambda \\
      8y + 8 & = 2\lambda \\
      x+2y-7 & = 0
    \end{align*}

    Third, solve the system of three equations and three unkowns. From the first two equations we have:
    \[
      2x-2 = 4y+4 \iff x=2y+3
    \]
    then plugging that into the third equation we have:
    \[
      (2y+3) + 2y-7 = 0.
    \]
    Solving for $y$ we have:
    \[
      y=1 \text{ and } x=5
    \]
    since $x=2y+3$.

    Fourth and final, substitute $y=1$ and $x=5$ into $F(x,y)$, and we have:
    \[
      F(5,1) = 5^2+4(1)^2-2(5)+8(1)=27.
    \]
  \end{explanation}
\end{example}

\section{Working with algebra}

We'll start with an example we did in our last section.

\begin{example}
Let $F(x,y) = 4x^3+4y^2-4x$ and let $C$ the set
\[
C = \{(x,y):x^2 + y^2 =1\}
\]
Find the maximum and minimum values of $F$ on $C$.
\begin{explanation}
  Start by setting $G(x,y) = x^2 + y^2$. The set $C$ is now the level
  curve $G(x,y) = \answer[given]{1}$. Now compute:
  \[
  \grad F(x,y) = \lambda \cdot \grad G(x,y)
  \]
  Write with me:
  \[
  \vector{\answer[given]{12x^2-4},\answer[given]{8y}} = \lambda \cdot \vector{\answer[given]{2x},\answer[given]{2y}}
  \]
  Breaking this vector equation into components, and adding in the constraint
  equation, the method of Lagrange multipliers gives us three
  equations and three unknowns:
  \begin{align*}
    \answer[given]{12x^2-4} &= \lambda 2x\\
    \answer[given]{8y} &= \lambda 2y\\
    \answer[given]{x^2 + y^2} &= 1
  \end{align*}
  To solve this system of equations, first note that if $y = 0$, then
  $x=\pm \answer[given]{1}$. This gives us two candidates for extrema:
  \[
  \left(1,\answer[given]{0}\right) \quad \text{and}\quad \left(-1,\answer[given]{0}\right)
  \]
  Now proceed assuming that $y\ne 0$. Looking at the second equation
  \[
  8y = \lambda 2y
  \]
  we can divide both sides by $2y$ to see that $\lambda = \answer[given]{4}$. Now we see that:
  \begin{align*}
    12x^2-4 &= \answer[given]{8x}\\
    3x^2-2x-1 &=0
  \end{align*}
  Solving this quadratic equation for $x$ we find
  \[
  x = \answer[given]{-1/3} \quad\text{and}\quad x = 1
  \]
  Now use the constraint equation $x^2 + y^2 =1$ to find $y$-values.
  From this we gain two more candidate for an extrema:
  \[
  \left(\frac{-1}{3},\answer[given]{\frac{-\sqrt{8}}{3}}\right) \quad\text{and}\quad\left(\answer[given]{\frac{-1}{3}},\frac{\sqrt{8}}{3}\right)
  \]
  Plugging these points back into $F$, we find that the minimum value of $F$ on $C$
  is $\answer[given]{0}$ and the maximum value is
  $\answer[given]{128/27}$.
\end{explanation}
\end{example}


Lagrange multipliers help out when when constraint set is given by an
implicit function. Let's see this in an example.


\begin{example}
Let $F(x,y) = x^2+2y^2-28x+51$ and let $M$ the set
\[
M = \{(x,y):y^2=x^3+1\}
\]
Find the maximum and minimum values of $F$ on $M$.
\begin{explanation}
  Start by setting $G(x,y) = x^3+1-y^2$. The set $M$ is now the level
  curve $G(x,y) = 0$. Now compute:
  \[
  \grad F(x,y) = \lambda \cdot \grad G(x,y)
  \]
  Write with me:
  \[
  \vector{\answer[given]{2x-28},\answer[given]{4y}} = \lambda \cdot \vector{\answer[given]{3x^2},\answer[given]{-2y}}
  \]
  Breaking this vector equation into components, and adding in the constraint
  equation, the method of Lagrange multipliers gives us three
  unknowns:
  \begin{align*}
    2x-28 &= \lambda 3x^2\\
    4y &= -\lambda 2y\\
    \answer[given]{x^3 + 1} &= y^2
  \end{align*}
  To solve this system of equations, first note that if $y = 0$, then
  $x=\answer[given]{-1}$. This gives us our first candidate for an extrema:
  \[
  \left(\answer[given]{-1},\answer[given]{0}\right)
  \]
  Now proceed assuming that $y\ne 0$. Looking at the second equation
  \[
  4y = -\lambda 2y
  \]
  we can divide both sides by $-2y$ to see that $\lambda = \answer[given]{-2}$. Now we see that:
  \begin{align*}
    2x-28&= -6x^2\\
    3x^2+x-14 &=0
  \end{align*}
  Solving this quadratic equation for $x$ we find
  \[
  x = \answer[given]{-7/3} \quad\text{and}\quad x = 2
  \]
  Now use the constraint equation $x^3+1=y^2$ to find $y$-values. If
  $x$ is $\answer[given]{-7/3}$, then $y$ is not a real number, so we will discard
  this solution. If $x=\answer[given]{2}$, then $y=\pm \answer[given]{3}$.  From this we gain two more
  candidate for an extrema:
  \[
  \left(\answer[given]{2},\answer[given]{-3}\right) \quad\text{and}\quad\left(2,3\right)
  \]
  Plugging these points back into $F$, we find that the minimum value
  of $F$ on $M$ is $\answer[given]{17}$ and the maximum value is
  $\answer[given]{80}$.
\end{explanation}
\end{example}

\begin{remark}
  The constraint curve used in the example above is called a \link[Mordell curve]{https://en.wikipedia.org/wiki/Mordell_curve}. The Mordell curve is a type of \link[elliptic curve]{https://en.wikipedia.org/wiki/Elliptic_curve}, a central object of study in number theory and cryptography. For much more information on the Mordell curve, see \link[this paper by Keith Conrad]{http://www.math.uconn.edu/~kconrad/blurbs/gradnumthy/mordelleqn1.pdf}.
\end{remark}



%% Another good example:
%% E is defined by the ellipic curve x^3-x=y^2
%% F is F(x,y) = x^2-y^2-2x

The method of Lagrange multipliers gives a unified method for solving a
large class of constrained optimization problems, and hence is used in
many areas of applied mathematics.


%% \section{The Lagrangian}

%% Finally, we should point our that there are other ways to view
%% Lagrange multipliers.

%% \begin{definition}
%%   Given functions $F:\R^n\to\R$ and $G:\R^n\to\R$ the \dfn{Lagrangian} is the function
%%   \[
%%   \mathcal{L}(\vec{x},\lambda) = F(\vec{x}) - \lambda \cdot G(\vec{x}).
%%   \]
%% \end{definition}

%% Thus to check whether
%% \[
%% \grad F(\vec{x}) = \lambda \cdot \grad G(\vec{x})
%% \]
%% is equivalent to checking where
%% \[
%% \grad \mathcal{L}(\vec{x},\lambda) = \vec{0}
%% \]
%% or has undefined components. When working with constrained
%% optimization problems by hand, the Lagrangian doesn't help much, since
%% your next step is to look at
%% \[
%% \grad \mathcal{L}(\vec{x},\lambda) = \vec{0}.
%% \]
%% However, there are certain advantages to working with the Lagrangian:
%% \begin{itemize}
%% \item If you are working with a computer, it might be better to work
%%   in terms of the Lagrangian, as there are efficient algorithms for
%%   checking when the gradient of the function is zero.
%% \item Working with the Lagrangian gives a method for changing
%%   ``constrained'' optimization to ``unconstrained'' optimization, as
%%   we are simply finding the critical points of
%%   $\mathcal{L}(\vec{x},\lambda)$.
%% \item The Lagrangian shows us a symmetry between $F$ and $G$.
%% \end{itemize}

For some interesting extra reading check out:
\begin{itemize}
\item \link[\textit{Unifying a Family of Extrema Problems},
  W.\ Barnier and D.\ Martin, College Math Journal, November
  1997]{http://www.jstor.org/stable/2687071}.
\item \link[\textit{An ``Extremely'' Cautionary Tale}, M.\ Krusemeyer, College Math Journal, March 2000]{http://www.jstor.org/stable/2687586}.
\item \link[\textit{Lagrange Multipliers Can Fail to Determine
    Extrema}, J.\ Nunemacher, College Math Journal, January
  2003]{http://www.jstor.org/stable/3595848}.
\item \link[\textit{On the Genesis of the Lagrange Multipliers}, P.\ Bussotti, Journal of Optimization Theory and Applications, June 2003]{http://rdcu.be/HZWI}.
\end{itemize}

\end{document}
